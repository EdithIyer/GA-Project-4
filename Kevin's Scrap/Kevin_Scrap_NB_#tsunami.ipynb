{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import plotly\n",
    "import html\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning:\n",
      "\n",
      "No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# I used Firefox; you can use whichever browser you like.\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "# Tell Selenium to get the URL you're interested in.\n",
    "browser.get(\"https://twitter.com/hashtag/tsunami?lang=en\")\n",
    "\n",
    "# Selenium script to scroll to the bottom, wait 3 seconds for the next batch of data to load, then continue scrolling.  It will continue to do this until the page stops loading new data.\n",
    "lenOfPage = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "match=False\n",
    "while(match==False):\n",
    "        lastCount = lenOfPage\n",
    "        time.sleep(1)\n",
    "        lenOfPage = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "        if lastCount==lenOfPage:\n",
    "            match=True\n",
    "\n",
    "# Now that the page is fully scrolled, grab the source code.\n",
    "source_data = browser.page_source\n",
    "\n",
    "# Throw your source into BeautifulSoup and start parsing!\n",
    "bs_data = bs(source_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#bs_data.find_all('p', {'class': 'TweetTextSize js-tweet-text tweet-text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IND_center'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(list(bs_data.find_all('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip'}))[10]).split('href=\"/')[1].split('/status')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Tweets Captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tweets = len(list(bs_data.find_all('p', {'class': 'TweetTextSize TweetTextSize--normal js-tweet-text tweet-text'})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doomalert19'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(list(bs_data.find_all('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip'}))[0]).split('href=\"/')[1].split('/status')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = str(list(bs_data.find_all('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip'}))[0]).split('title=\"')[1].split('\"><span ')[0].split(' - ')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_str = str(list(bs_data.find_all('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip'}))[0]).split('title=\"')[1].split('\"><span ')[0].split('-')[1].lstrip().split(' ')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_str = str(list(bs_data.find_all('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip'}))[0]).split('title=\"')[1].split('\"><span ')[0].split('-')[1].lstrip().split(' ')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_str = str(list(bs_data.find_all('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip'}))[0]).split('title=\"')[1].split('\"><span ')[0].split('-')[1].lstrip().split(' ')[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#datetime_object = datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10:21AM'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_object = datetime.strptime(month_str + ' ' + day_str + ' ' + year_str + ' ' + time_str.replace(\" \", \"\"), '%b %d %Y %I:%M%p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tweet = str(list(bs_data.find_all('p', {'class': 'TweetTextSize TweetTextSize--normal js-tweet-text tweet-text'}))[0]).split('lang=\"en\">')[1].split('<a class')[0].rstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for keyword (tsunami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = 'This is a tweet about a #tsunami'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'#tsunami' in tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "\n",
    "temp_dict['handle']     = str(list(bs_data.find_all('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip'}))[0]).split('href=\"/')[1].split('/status')[0]\n",
    "temp_dict['tweet']      = str(list(bs_data.find_all('p', {'class': 'TweetTextSize TweetTextSize--normal js-tweet-text tweet-text'}))[0]).split('lang=\"en\">')[1].split('<a class')[0].rstrip()\n",
    "temp_dict['datetime']   = datetime_object\n",
    "temp_dict['if_tsunami'] = 'tsunami' in temp_dict['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'handle': 'thejakartaglobe',\n",
       " 'tweet': 'China Pledges Easier Foreign Tourist Access to Tibet Amid US Pressure',\n",
       " 'datetime': datetime.datetime(2019, 1, 13, 6, 25),\n",
       " 'if_tsunami': False}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_data.find_all('p', {'class': 'TweetTextSize TweetTextSize js-tweet-text tweet-text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "master_list = []\n",
    "#loop_range = num_tweets - 1\n",
    "loop_range = 10\n",
    "\n",
    "\n",
    "for i in range(loop_range):\n",
    "    tweets = bs_data.find_all('p', {'class': 'TweetTextSize js-tweet-text tweet-text'})\n",
    "\n",
    "    temp_dict = {}\n",
    "\n",
    "    temp_dict['handle']     = str(list(bs_data.find_all('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip'}))[i]).split('href=\"/')[1].split('/status')[0]\n",
    "    \n",
    "    try:\n",
    "        temp_dict['tweet']      = str(tweets[i].get_text()).replace(\"\\n\", \" \")\n",
    "        #temp_dict['tweet']      = str(list(bs_data.find_all('p', {bs_data.find_all('p', {'class': 'TweetTextSize js-tweet-text tweet-text'})[i].split('lang=\"en\">')[1].split('<a class')[0].rstrip()\n",
    "    except IndexError:\n",
    "        temp_dict['tweet']      = \"\"\n",
    "    \n",
    "    temp_dict['day']        = str(list(bs_data.find_all('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip'}))[i]).split('title=\"')[1].split('\"><span ')[0].split('-')[1].lstrip().split(' ')[0]\n",
    "    temp_dict['month']      = str(list(bs_data.find_all('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip'}))[i]).split('title=\"')[1].split('\"><span ')[0].split('-')[1].lstrip().split(' ')[1]\n",
    "    temp_dict['year']       = str(list(bs_data.find_all('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip'}))[i]).split('title=\"')[1].split('\"><span ')[0].split('-')[1].lstrip().split(' ')[2]\n",
    "    temp_dict['time']       = str(list(bs_data.find_all('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip'}))[i]).split('title=\"')[1].split('\"><span ')[0].split(' - ')[0]\n",
    "    \n",
    "    datetime_object = datetime.strptime(temp_dict['month'] + ' ' + temp_dict['day'] + ' ' + temp_dict['year'] + ' ' + temp_dict['time'].replace(\" \", \"\"), '%b %d %Y %I:%M%p')\n",
    "    \n",
    "    temp_dict['datetime']   = datetime_object\n",
    "    temp_dict['if_tsunami'] = 'tsunami' in temp_dict['tweet'] or 'Tsunami' in tweet or '#tsunami' in tweet or '#Tsunami' in tweet\n",
    "    \n",
    "    master_list.append(temp_dict)\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'handle': 'SSkyvington',\n",
       " 'tweet': '#Tsunami  Three health care tsunamis — obesity, diabetes, and dementia — are waiting for us, for boomers and zoomers especially, looming just on the horizon, building up speed, and threatening to swamp our health care system and wipe out the treasury.  https://www.dundurn.com/books/May-Hurt-Bit\\xa0…https://twitter.com/NeilFlochMD/status/1084796525509857281\\xa0…',\n",
       " 'day': '14',\n",
       " 'month': 'Jan',\n",
       " 'year': '2019',\n",
       " 'time': '5:00 AM',\n",
       " 'datetime': datetime.datetime(2019, 1, 14, 5, 0),\n",
       " 'if_tsunami': True}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(master_list).to_csv('thejakartaglobe_tweetscrape.csv', sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = 'this is a tweet with Tsunami in it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'tsunami' in tweet or 'Tsunami' in tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-33-46f27fef284e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-33-46f27fef284e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    str(list(bs_data.find_all('p', {bs_data.find_all('p', {'class': 'TweetTextSize js-tweet-text tweet-text'})[0].split('lang=\"en\">')[1].split('<a class')[0].rstrip()\u001b[0m\n\u001b[0m                                                                                                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "str(list(bs_data.find_all('p', {bs_data.find_all('p', {'class': 'TweetTextSize js-tweet-text tweet-text'})[0].split('lang=\"en\">')[1].split('<a class')[0].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Are'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(list(bs_data.find_all('p', {'class': 'TweetTextSize js-tweet-text tweet-text'}))[9]).split('lang=\"en\">')[1].split('<a class')[0].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p class=\"TweetTextSize js-tweet-text tweet-text\" data-aria-label-part=\"0\" lang=\"en\">Real-time updates <a class=\"twitter-atreply pretty-link js-nav\" data-mentioned-user-id=\"1006255208379211776\" dir=\"ltr\" href=\"/DisasterawareE\"><s>@</s><b>DisasterAWAREE</b></a> for 78 currently on-going active natural hazards around the world! <a class=\"twitter-hashtag pretty-link js-nav\" data-query-source=\"hashtag_click\" dir=\"ltr\" href=\"/hashtag/highsurf?src=hash\"><s>#</s><b>highsurf</b></a> <a class=\"twitter-hashtag pretty-link js-nav\" data-query-source=\"hashtag_click\" dir=\"ltr\" href=\"/hashtag/WinterStorm?src=hash\"><s>#</s><b>WinterStorm</b></a> <a class=\"twitter-hashtag pretty-link js-nav\" data-query-source=\"hashtag_click\" dir=\"ltr\" href=\"/hashtag/flood?src=hash\"><s>#</s><b>flood</b></a> <a class=\"twitter-hashtag pretty-link js-nav\" data-query-source=\"hashtag_click\" dir=\"ltr\" href=\"/hashtag/earthquake?src=hash\"><s>#</s><b>earthquake</b></a> <a class=\"twitter-hashtag pretty-link js-nav\" data-query-source=\"hashtag_click\" dir=\"ltr\" href=\"/hashtag/volcano?src=hash\"><s>#</s><b>volcano</b></a> <a class=\"twitter-hashtag pretty-link js-nav\" data-query-source=\"hashtag_click\" dir=\"ltr\" href=\"/hashtag/wildfire?src=hash\"><s>#</s><b>wildfire</b></a> <a class=\"twitter-hashtag pretty-link js-nav\" data-query-source=\"hashtag_click\" dir=\"ltr\" href=\"/hashtag/tsunami?src=hash\"><s>#</s><b><strong>tsunami</strong></b></a> <a class=\"twitter-hashtag pretty-link js-nav\" data-query-source=\"hashtag_click\" dir=\"ltr\" href=\"/hashtag/ExtremeWeather?src=hash\"><s>#</s><b>ExtremeWeather</b></a> <a class=\"twitter-hashtag pretty-link js-nav\" data-query-source=\"hashtag_click\" dir=\"ltr\" href=\"/hashtag/droughts?src=hash\"><s>#</s><b>droughts</b></a><a class=\"twitter-timeline-link u-hidden\" data-pre-embedded=\"true\" dir=\"ltr\" href=\"https://t.co/wIhmh73Ufl\">pic.twitter.com/wIhmh73Ufl</a></p>'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(list(bs_data.find_all('p', {'class': 'TweetTextSize js-tweet-text tweet-text'}))[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 579)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(loop_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thejakartaglobe'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(list(bs_data.find_all('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip'}))[579]).split('href=\"/')[1].split('/status')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(list(bs_data.find_all('p', {'class': 'TweetTextSize TweetTextSize--normal js-tweet-text tweet-text'}))[5]).split('lang=\"en\">')[1].split('<a class')[0].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
